import streamlit as st
import cv2
import numpy as np
import threading
from tensorflow.keras.models import load_model
from tensorflow.keras.layers import Layer
import tempfile
import pyttsx3  # ‡πÉ‡∏ä‡πâ pyttsx3 ‡πÅ‡∏ó‡∏ô pygame
from gtts import gTTS
import time
import os

# ‡∏Ñ‡∏•‡∏≤‡∏™ Custom Layer
class CastLayer(Layer):
    def call(self, inputs):
        return inputs

# ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•
@st.cache_resource
def load_emotion_model():
    model_path = "model_emotion.h5"
    return load_model(model_path, custom_objects={"Cast": CastLayer}, compile=False)

# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå
def predict_emotion(face, model):
    face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)
    face = cv2.equalizeHist(face)  
    face = cv2.resize(face, (48, 48)) / 255.0
    face = np.expand_dims(face, axis=-1)  
    face = np.expand_dims(face, axis=0)  

    predictions = model.predict(face)
    labels = ['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']
    return labels[np.argmax(predictions)]

# ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ pyttsx3 ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏û‡∏π‡∏î
engine = pyttsx3.init()
engine.setProperty('rate', 150)  # ‡∏õ‡∏£‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß‡∏Ç‡∏≠‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡∏á
engine.setProperty('volume', 1)  # ‡∏õ‡∏£‡∏±‡∏ö‡∏£‡∏∞‡∏î‡∏±‡∏ö‡πÄ‡∏™‡∏µ‡∏¢‡∏á (0.0 ‡∏ñ‡∏∂‡∏á 1.0)

is_speaking = False  

# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏û‡∏π‡∏î
def speak(text):
    global is_speaking

    if is_speaking:
        return
    
    is_speaking = True  

    def play_audio():
        global is_speaking
        engine.say(text)
        engine.runAndWait()
        is_speaking = False

    threading.Thread(target=play_audio, daemon=True).start()


# ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•
model = load_emotion_model()

# ‚úÖ **‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô show() ‡∏ï‡∏£‡∏á‡∏ô‡∏µ‡πâ**
def show():
    st.title("üé≠ Real-time Emotion Detection")
    run = st.checkbox("üì∏ ‡πÄ‡∏õ‡∏¥‡∏î‡∏Å‡∏•‡πâ‡∏≠‡∏á")

    emotion_speech = {
        "Angry": "‡∏Ñ‡∏∏‡∏ì‡∏î‡∏π‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå‡πÑ‡∏°‡πà‡∏î‡∏µ‡∏ô‡∏∞ ‡πÉ‡∏à‡πÄ‡∏¢‡πá‡∏ô‡πÜ ‡∏ô‡∏∞‡∏Ñ‡∏£‡∏±‡∏ö",
        "Disgust": "‡∏î‡∏π‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏ß‡πà‡∏≤‡∏Ñ‡∏∏‡∏ì‡∏à‡∏∞‡∏£‡∏π‡πâ‡∏™‡∏∂‡∏Å‡∏Ç‡∏¢‡∏∞‡πÅ‡∏Ç‡∏¢‡∏á",
        "Fear": "‡∏Ñ‡∏∏‡∏ì‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏£‡∏π‡πâ‡∏™‡∏∂‡∏Å‡∏Å‡∏•‡∏±‡∏ß‡∏´‡∏£‡∏∑‡∏≠‡∏Å‡∏±‡∏á‡∏ß‡∏•‡∏≠‡∏¢‡∏π‡πà‡∏´‡∏£‡∏∑‡∏≠‡πÄ‡∏õ‡∏•‡πà‡∏≤",
        "Happy": "‡∏ß‡∏±‡∏ô‡∏ô‡∏µ‡πâ‡∏Ñ‡∏∏‡∏ì‡∏î‡∏π‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∏‡∏Ç",
        "Sad": "‡∏Ñ‡∏∏‡∏ì‡∏î‡∏π‡πÄ‡∏®‡∏£‡πâ‡∏≤ ‡∏Ç‡∏≠‡πÉ‡∏´‡πâ‡∏ó‡∏∏‡∏Å‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏î‡∏µ‡∏Ç‡∏∂‡πâ‡∏ô‡∏ô‡∏∞",
        "Surprise": "‡∏Ñ‡∏∏‡∏ì‡∏î‡∏π‡∏ï‡∏Å‡πÉ‡∏à ‡∏°‡∏µ‡∏≠‡∏∞‡πÑ‡∏£‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡∏∂‡πâ‡∏ô‡∏´‡∏£‡∏≠",
        "Neutral": "‡∏Ñ‡∏∏‡∏ì‡∏î‡∏π‡∏õ‡∏Å‡∏ï‡∏¥ ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏≠‡∏∞‡πÑ‡∏£‡πÄ‡∏õ‡πá‡∏ô‡∏û‡∏¥‡πÄ‡∏®‡∏©"
    }

    if run:
        cap = cv2.VideoCapture(0)
        stframe = st.empty()
        stop_button = st.button("üî¥ ‡∏õ‡∏¥‡∏î‡∏Å‡∏•‡πâ‡∏≠‡∏á")

        last_emotion = None  
        face_detected = False  

        while cap.isOpened():
            ret, frame = cap.read()
            if not ret or stop_button:
                st.warning("üìå ‡∏Å‡∏•‡πâ‡∏≠‡∏á‡∏ñ‡∏π‡∏Å‡∏õ‡∏¥‡∏î‡πÅ‡∏•‡πâ‡∏ß")
                break

            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
            face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + "haarcascade_frontalface_default.xml")
            faces = face_cascade.detectMultiScale(gray, 1.3, 5)

            if len(faces) > 0:
                face_detected = True  
            else:
                face_detected = False  
                last_emotion = None  

            for (x, y, w, h) in faces:
                face = frame[y:y+h, x:x+w]
                emotion = predict_emotion(face, model)

                if emotion != last_emotion:
                    if not is_speaking:
                        speak(emotion_speech.get(emotion, ""))
                        last_emotion = emotion  

                cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)
                cv2.putText(frame, emotion, (x + 5, y + h + 25), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2, cv2.LINE_AA)

            stframe.image(frame, channels="BGR")
        
        cap.release()
    else:
        st.warning("üìå ‡∏Å‡∏î‡πÄ‡∏õ‡∏¥‡∏î‡∏Å‡∏•‡πâ‡∏≠‡∏á‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô")
